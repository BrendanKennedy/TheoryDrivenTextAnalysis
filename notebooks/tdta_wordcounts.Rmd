---
title: "Theory Driven Text Analysis Workshop"
subtitle: "Dictionary Methods --- Word counts \n\nSPSP 2020"
author: 
  name: "Joe Hoover & Brendan Kennedy"
  email: "joseph.hoover@kellogg.northwestern.edu\n\nbtkenned@usc.edu"
output:
  html_notebook:
    toc: yes
---


# Overview

In this module, we will explore dictionary-based word count approaches text analysis measurement. 

We will be working with U.S. House floor speeches spanning June 1998 through July 1999. More specifically, we will:

(1) investigate variations in sentiment as a function of political party
(2) explore sentiment dynamics in the context of President Bill Clinton's impeachment. 


# Environment Preparation
```{r, echo=F, message=F, warning=F}
# Define chunk options
knitr::opts_chunk$set(echo=T, message=F, warning=F)
```

```{r, message=F,  echo=T}
# Load packages 
library(pacman)
p_load(readr, dplyr, tidyr, ggplot2, jtools, 
       knitr, reshape2, jsonlite, lubridate, sentimentr, magrittr)

```

# Data Preparation 

In the preprocessing module (`../notebooks/tdta_preprocessing.Rmd`), we saved a tidy format data.frame containing our corpus. We'll use that as a starting point for our work in this module.

```{r}

dat_tidy <- readRDS('../data/tdta_clean_house_data_tidy.RDS')

dat_tidy

```


In this data.frame, words are stored in the cells of the column `word`. Accordingly, an entire document, identified by the unique document identifier `doc_num`, is stored across multiple rows. This data.frame also contains metadata like the name of the speaker associated with a given document, as well as the the speaker's party, district, and State.


## Train/Test Split 

If you have enough data, there's really _never_ any reason to not separate your data into a training set and testing set. Of course, determing how much data is *enough* can be tricky, because you don't want to create a situation where you are underpowered or unable to estimate a target parameter with sufficient precision. 

However, treating documents as our units of observation, we have an $N = $ 35,959, which is probably large enough for splitting.

```{r}

doc_ids <- unique(dat_tidy$doc_num) # Get document IDs

n_docs = .50 * length(doc_ids) # Calculate number of documents to sample

set.seed(5435) # set seed for reproducibility

doc_ids_test = sample(doc_ids, n_docs) # sample document IDs for test data

dat_tidy.train <- dat_tidy %>%
  filter(doc_num %!in% doc_ids_test) # Select documents for training

dat_tidy.test <- dat_tidy %>%
  filter(doc_num %in% doc_ids_test) # Select documents for test


```



## Conducting Word counts

### Introduction to dictionaries

To conduct word count analyses, you need a *dictionary* or *lexicon* that specifies the words associated with your target construct(s). 

To start, we'll work with the NRC sentiment dictionary, which is one of three sentiment dictionaries packaged with `tidytext`: 

1. AFINN
2. bing
3. nrc

To access the NRC dictionary, we'll use the `get_sentiments` function to store the NRC dictionary in an object called `nrc_sent`.

```{r}
nrc_sent <- get_sentiments('nrc')
nrc_sent
```

`nrc_sent` contains two columns, `word`, which contains the words in the dictionary, and `sentiment`, which specifies the sentiment label associated with the word. 

```{r}
nrc_sent %>%
  count(sentiment)
```

The NRC dictionary contains 10 sentiment categories and each of these categories have varying numbers of words associated with them. 

Let's take a glance at first words in each category by spreading our tidy data.frame:

```{r}
nrc_sent %>%
  group_by(sentiment) %>% 
  mutate(temp_id = row_number()) %>% # Create a temporary ID to weight top_n by
  top_n(n = -50, wt=temp_id) %>%     # Get first 50 items in each group 
  mutate(temp_id = row_number()) %>% # Create a temporary unique ID for each word in each group
  ungroup() %>%
  pivot_wider(names_from = sentiment, values_from = word) %>% # Spread our data
  select(-temp_id)
```


Glancing at these words, it's clear that words are repeated in some categories. 


<br>

<div class="alert alert-success" role="alert">
  <strong>Question:</strong> What other characteristics stand out, if any?
</div>


### `tidytext` word count sentiment analysis

In principle, `tidytext` makes simple dictionary-based word count sentiment analysis quite simple. 

To count the words we can just: 

1. Conduct an `inner_join` between our data and our sentiment dictionary
2. Count the matches

We'll also divide the number of matches for each sentiment domain by the total number of words in our corpus. This will tell us the proportion associated with each sentiment domain.

```{r}

total_words = nrow(dat_tidy.train)

dat_tidy.train %>%
  inner_join(nrc_sent) %>%
  count(sentiment) %>%
  mutate(prop = n/total_words) %>%
  arrange(desc(prop))

```


### Affective sentiment by Political Party

We can also subset our data in order to ask more specific questions. For instance, we can easily estimate sentiment proportions for Democrats and Republicans.

```{r}

dat_tidy.train.sent <- dat_tidy.train %>%
  group_by(Party) %>% # Group by Party
  mutate(total_words = n()) %>% # Calculate the total words in each group
  ungroup() %>% 
  inner_join(nrc_sent) # Drop words that aren't in sentiment dictionary
  
dat_tidy.train.sent %>% count(total_words, Party, sentiment) %>% # Count the number of rows in each Party for each sentiment
  mutate(prop = n/total_words) %>% # Calculate the proportion
  arrange(desc(prop)) %>% # Arrange in descending order by proportion positive
  select(-n, -total_words) %>%
  pivot_wider(names_from='Party', values_from = 'prop')



```


Overall, it looks like there is very little mean sentiment variation between Republicans and Democrats. However, we've collapsed across documents. To get a better idea of how expressions of affective sentiment vary across Parties, let's visualize the distribution of sentiment in documents 



```{r}
 
dat_tidy.train.sent %>%
  filter(Party !='Independent') %>%
  count(total_words, Party, doc_num, sentiment) %>%
  mutate(prop = n/total_words) %>%
  ggplot(aes(y = prop, x = Party, color=Party)) + 
  geom_jitter(alpha=.25) + 
  facet_wrap(.~sentiment, ncol=5) + 
  scale_colour_manual(values = c("blue", "red")) +
  theme_apa() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle('Document-level proportions of sentiment words by party') + 
  xlab('Party') + 
  ylab('Proportion')

```


What if we look at the document *N*s of sentiment words instead of proportions?

```{r}
 
dat_tidy.train.sent %>%
  filter(Party !='Independent') %>%
  count(total_words, Party, doc_num, sentiment) %>%
  mutate(prop = n/total_words) %>%
  ggplot(aes(y = n, x = Party, color=Party)) + 
  geom_jitter(alpha=.25) + 
  facet_wrap(.~sentiment, ncol=5) + 
  scale_colour_manual(values = c("blue", "red")) +
  theme() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle('Document-level Ns of sentiment words by party') + 
  xlab('Party') + 
  ylab('N')

```



<br>

<div class="alert alert-success" role="alert">
  <strong>Question:</strong> Why might we want to look at proportion vs. N (or vice versa)?
</div>


### Dynamics in affective sentiment by political party

Clearly, there isn't much marginal between group variation in affective sentiment in this dataset. However, maybe there are interesting effects operating at other levels!

Let's examine temporal variation in affective sentiment between parties. To do this, we will take a similar approach, but instead of counting the sentiment in each document, we'll count the sentiment on each observed day. 

First, however, let's glance at the distribution of documents across time. For reference, let's also add vertical lines to indicate the dates on which Clinton's impeachment was iniated and voted on.



```{r, fig.width=10}

sent_time <- dat_tidy.train.sent %>%
  filter(Party !='Independent') %>%
  distinct(doc_num, .keep_all = T) %>%
  count(date, Party) %>%
  ggplot(aes(y = n, x = date, color=Party)) + 
  geom_line(alpha=.5) + 
  facet_wrap(Party ~. , ncol=1) +
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  geom_point() +
  theme_apa() +
  ggtitle('N of documents across time by party') +
  ylab('N') + 
  xlab('Date')

ggplotly(sent_time)


```

Clearly, there is substantial variation in the number of documents (i.e. speeches given by individual speakers) across time. 


<br>

<div class="alert alert-success" role="alert">
  <strong>Question:</strong> What are our sample sizes on the impeachment-relevant days?
</div>



Now, let's plot sentiment across time by party. 

```{r, fig.height=10, fig.width=10}

dat_tidy.train.sent %>%
  filter(Party !='Independent') %>%
  count(total_words, Party, date, sentiment) %>%
  mutate(prop = n/total_words) %>%
  ggplot(aes(y = n, x = date, color=Party)) + 
  facet_wrap(sentiment~Party, ncol=4) + 
  scale_colour_manual(values = c("blue", "red")) +
  theme() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle('Document-level Ns of sentiment words by party') + 
  xlab('Party') + 
  ylab('N') + 
  geom_smooth(color='black') +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2) +
  geom_point(alpha=.25) 

```



```{r, fig.height=10, fig.width=10}

dat_tidy.train.sent %>%
  filter(Party !='Independent') %>%
  count(total_words, Party, date, sentiment) %>%
  mutate(prop = n/total_words) %>%
  ggplot(aes(y = prop, x = date, color=Party)) + 
  facet_wrap(sentiment~Party, ncol=4) + 
  scale_colour_manual(values = c("blue", "red")) +
  theme() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  ggtitle('Document-level proportions of sentiment words by party') + 
  xlab('Party') + 
  ylab('N') + 
  geom_smooth(color='black') +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2) +
  geom_point(alpha=.25) 

```


<br>

<div class="alert alert-success" role="alert">
  <strong>Question:</strong> What can we learn from this figure?
</div>


## Hypothesis testing with word counts

```{r}

dat_tidy.train.speaker <- dat_tidy.train %>%
  group_by(Party, speaker) %>%
  mutate(speaker_total_words = n()) %>%
  ungroup() %>%
  inner_join(nrc_sent) %>%
  count(Party, speaker, speaker_total_words, date, sentiment) %>%
  group_by(speaker, sentiment) %>%
  mutate(speaker_sent_means = mean(n), 
         speaker_sent_cntr = n - speaker_sent_means)
  
```



```{r}

dat_tidy.train.speaker <- dat_tidy.train %>%
  filter(Party != 'Independent') %>%
  group_by(Party, speaker, date) %>%
  mutate(speaker_day_n = n()) %>%
  ungroup() %>%
  inner_join(nrc_sent) %>%
  count(Party, speaker, date, speaker_day_n, sentiment) %>%
  mutate(speaker_day_sent_prop = n/speaker_day_n)




# Create a date range from the min/max dates in our training data
date_grid <- tibble(date = seq(min(dat_tidy.train.speaker$date), 
                               max(dat_tidy.train.speaker$date), by='days')) %>%
  mutate(date_int = row_number(), # Associate each date with an integer 
         date_int_scaled = date_int/100)

dat_tidy.train.speaker <- dat_tidy.train.speaker %>%
  left_join(date_grid) %>%
  mutate(date_int_scaled = date_int/100, 
         impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))
  
```


### Negative sentiment

```{r}

train.speaker.negative.m1 <- dat_tidy.train.speaker %>%
  filter(sentiment=='negative') %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1  | speaker) + (1 + Party | date_int), data=.)

summary(train.speaker.negative.m1)

```



```{r}


dat_tidy.train.speaker.pred_grid <- expand.grid(Party = unique(dat_tidy.train.speaker$Party), 
            speaker = 'new_speaker', 
            date_int = unique(dat_tidy.train.speaker$date_int))


dat_tidy.train.speaker.pred_grid <- dat_tidy.train.speaker.pred_grid %>%
  left_join(date_grid) %>%
  mutate(impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))



train.speaker.negative.m1.pred <- dat_tidy.train.speaker.pred_grid %>%
  mutate(preds = predict(train.speaker.negative.m1, newdata=dat_tidy.train.speaker.pred_grid, allow.new.levels=T))
  


train.speaker.negative.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of negative language for an average speaker' ) +
  ylab('Speaker proportion negative language') + 
  xlab('Date')

  
```



### Disgust 

```{r}


train.speaker.disgust.m1 <- dat_tidy.train.speaker %>%
  filter(sentiment=='disgust') %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1  | speaker) + (1 + Party | date_int), data=.)

summary(train.speaker.disgust.m1)



train.speaker.disgust.m1.pred <- dat_tidy.train.speaker.pred_grid %>%
  mutate(preds = predict(train.speaker.disgust.m1, newdata=dat_tidy.train.speaker.pred_grid, allow.new.levels=T))
  


train.speaker.disgust.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date')


```


### All sentiment

```{r}



train.speaker.all.m1 <- dat_tidy.train.speaker %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1 | speaker) + (1 + Party | date_int) + (1 + impeachment_1  + impeachment_2 | sentiment), data=.)

summary(train.speaker.all.m1)


dat_tidy.train.speaker.pred_grid.all_sent <- expand.grid(Party = unique(dat_tidy.train.speaker$Party), 
            speaker = 'new_speaker', 
            date_int = unique(dat_tidy.train.speaker$date_int),
            sentiment=unique(dat_tidy.train.speaker$sentiment))


dat_tidy.train.speaker.pred_grid.all_sent <- dat_tidy.train.speaker.pred_grid.all_sent %>%
  left_join(date_grid) %>%
  mutate(impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))


train.speaker.all.m1.pred <- dat_tidy.train.speaker.pred_grid.all_sent %>%
  mutate(preds = predict(train.speaker.all.m1, 
                         newdata=dat_tidy.train.speaker.pred_grid.all_sent, 
                         allow.new.levels=T))
  

```



```{r, fig.width=10, fig.height=6}
train.speaker.all.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date') + facet_wrap(sentiment~., ncol=2)

```



```{r, fig.width=10, fig.height=6}
train.speaker.all.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date') + facet_wrap(sentiment~., ncol=2, scales='free_y')


```



```{r}
sjPlot::plot_model(train.speaker.all.m1, type='re')[3]
```


## Confirmation 


```{r}

dat_tidy.test.speaker <- dat_tidy.test %>%
  group_by(Party, speaker) %>%
  mutate(speaker_total_words = n()) %>%
  ungroup() %>%
  inner_join(nrc_sent) %>%
  count(Party, speaker, speaker_total_words, date, sentiment) %>%
  group_by(speaker, sentiment)
  
```



```{r}

dat_tidy.test.speaker <- dat_tidy.test %>%
  filter(Party != 'Independent') %>%
  group_by(Party, speaker, date) %>%
  mutate(speaker_day_n = n()) %>%
  ungroup() %>%
  inner_join(nrc_sent) %>%
  count(Party, speaker, date, speaker_day_n, sentiment) %>%
  mutate(speaker_day_sent_prop = n/speaker_day_n)




# Create a date range from the min/max dates in our testing data
date_grid <- tibble(date = seq(min(dat_tidy.test.speaker$date), 
                               max(dat_tidy.test.speaker$date), by='days')) %>%
  mutate(date_int = row_number(), # Associate each date with an integer 
         date_int_scaled = date_int/100)

dat_tidy.test.speaker <- dat_tidy.test.speaker %>%
  left_join(date_grid) %>%
  mutate(date_int_scaled = date_int/100, 
         impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))
  
```


### Negative

```{r}

test.speaker.negative.m1 <- dat_tidy.test.speaker %>%
  filter(sentiment=='negative') %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1  | speaker) + (1 + Party | date_int), data=.)

summary(test.speaker.negative.m1)

```



```{r}


dat_tidy.test.speaker.pred_grid <- expand.grid(Party = unique(dat_tidy.test.speaker$Party), 
            speaker = 'new_speaker', 
            date_int = unique(dat_tidy.test.speaker$date_int))


dat_tidy.test.speaker.pred_grid <- dat_tidy.test.speaker.pred_grid %>%
  left_join(date_grid) %>%
  mutate(impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))



test.speaker.negative.m1.pred <- dat_tidy.test.speaker.pred_grid %>%
  mutate(preds = predict(test.speaker.negative.m1, newdata=dat_tidy.test.speaker.pred_grid, allow.new.levels=T))
  


test.speaker.negative.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of negative language for an average speaker' ) +
  ylab('Speaker proportion negative language') + 
  xlab('Date')

  
```



### Disgust 

```{r}


test.speaker.disgust.m1 <- dat_tidy.test.speaker %>%
  filter(sentiment=='disgust') %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1  | speaker) + (1 + Party | date_int), data=.)

summary(test.speaker.disgust.m1)



test.speaker.disgust.m1.pred <- dat_tidy.test.speaker.pred_grid %>%
  mutate(preds = predict(test.speaker.disgust.m1, newdata=dat_tidy.test.speaker.pred_grid, allow.new.levels=T))
  


test.speaker.disgust.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date')


```


### All sentiment 

```{r}



test.speaker.all.m1 <- dat_tidy.test.speaker %>%
  lmer(speaker_day_sent_prop ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1 | speaker) + (1 + Party | date_int) + (1 + impeachment_1  + impeachment_2 | sentiment), data=.)

summary(test.speaker.all.m1)


dat_tidy.test.speaker.pred_grid.all_sent <- expand.grid(Party = unique(dat_tidy.test.speaker$Party), 
            speaker = 'new_speaker', 
            date_int = unique(dat_tidy.test.speaker$date_int),
            sentiment=unique(dat_tidy.test.speaker$sentiment))


dat_tidy.test.speaker.pred_grid.all_sent <- dat_tidy.test.speaker.pred_grid.all_sent %>%
  left_join(date_grid) %>%
  mutate(impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))


test.speaker.all.m1.pred <- dat_tidy.test.speaker.pred_grid.all_sent %>%
  mutate(preds = predict(test.speaker.all.m1, 
                         newdata=dat_tidy.test.speaker.pred_grid.all_sent, 
                         allow.new.levels=T))
  

```



```{r, fig.width=10, fig.height=6}
test.speaker.all.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date') + facet_wrap(sentiment~., ncol=2)

```



```{r, fig.width=10, fig.height=6}

test.speaker.all.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of disgust language for an average speaker' ) +
  ylab('Speaker proportion disgust language') + 
  xlab('Date') + facet_wrap(sentiment~., ncol=2, scales='free_y')


```



```{r}
sjPlot::plot_model(test.speaker.all.m1, type='re')[3]
```



### Validation, validation, validation!

No matter what you're trying to measure or what measurement methods you're using, you should _always_ closely examine what you are _actually_ measuring. 

Coincidentally, there's a very relevant quote from Bill Clinton:

From the (Wikipedia entry)[https://en.wikipedia.org/wiki/Impeachment_of_Bill_Clinton] for Clinton's impeachment

A much-quoted statement from Clinton's grand jury testimony showed him questioning the precise use of the word "is". Contending his statement that "there's nothing going on between us" had been truthful because he had no ongoing relationship with Lewinsky at the time he was questioned, Clinton said: "It depends upon what the meaning of the word 'is' is..."

So what are we measuring when we count words? What are we measuring with NRC lexicon? 


<div class="alert alert-success" role="alert">
  <strong>Question:</strong> So what are we measuring when we count words? What are we measuring with NRC lexicon? Are we really measuring what we think we are?
</div>


Let's take a look! 

```{r}

text_dat <- readRDS('../data/tdta_clean_house_data.RDS')

top_docs <- dat_tidy.train %>%
  group_by(doc_num) %>%
  mutate(doc_total_words = n()) %>%
  ungroup() %>%
  inner_join(nrc_sent) %>%
  count(doc_num, doc_total_words, sentiment) %>%
  mutate(sent_prop = n/doc_total_words) %>%
  group_by(sentiment) %>%
  top_n(3, wt=n) %>%
  left_join(text_dat %>% select(doc_num, text))



top_docs %>%
  filter(sentiment=='negative') %>%
  arrange(desc(sent_prop)) %>%
  mutate(text_seg = str_sub(text, 1,2000)) %>%
  select(-text) %>%
  View()
 

```


Because the documents are so long, it's actually quite hard to evaluate the veracity of our measurement. Another option is to look at the most frequent sentiment words in our corpus.

```{r}

top_words <- dat_tidy.train.sent %>%
  count(sentiment, word) %>%
  group_by(sentiment) %>%
  top_n(10, wt=n) %>%
  mutate(temp_id = row_number()) %>%
  ungroup() %>%
  select(-n) %>%
  pivot_wider(names_from=sentiment, values_from=word) %>%
  select(-temp_id)

top_words
 

```



<div class="alert alert-success" role="alert">
  <strong>Question:</strong> What can we learn from looking at these words? How do you feel about our analyses?
</div>


One of the greatest strengths of dictionary-based text measurement methods is that they allow you to precisely define the construct you are interested in. This works extremely well when you are interested in specific words or types of words. 

For example, if you are interested in *function words*, then it would never make sense to use anything other than a dictionary-based approach. Similarly, if you are truly interested in the usage of *positive* or *negative* words, then, again, it probably wouldn't make sense to use anything other than a dictionary approach. 

In these examples, there is a 1:1 relationship between the target construct and the operationalization. However, this 1:1 relationship is difficult to maintain for more abstract constructs, like "positive sentiment" or "negative sentiment". In such cases, you (or someone else) has to decide which words evoke "positive sentiment" or "negative sentiment". 

Further, we are often interested in expressions of meaning that may operate above the word level. For instance, consider the following example: 

`Let's just say...I didn't love it'

Most dictionary-based word count methods would estimate the sentiment expressed in this sentence as "positive" because of the token `love`. However, considering the entire *context* of this example, we can infer that the most likely sentiment is probably "negative". Another issue related to context sensitivity is domain dependence: a word might have negative connotations in some discourse communities, but not in others.

In sum, dictionary-based word count approaches can be quite powerful; however, they have two notable shortcomings: 

1. Dependence on dictionary validity
2. Cannot account for context

This *does not* mean that you shouldn't use dictionary-based word count methods. However, it *does* mean that you should keep these short comings in mind. And, even better, you should try to account for them. 

# Doing better than simple word counts 

In response to some of the issues raised above, people have started trying to improve on word count methods, for instance by accounting for negation or assigning weights to sentiment words. In `R`, you can use the `sentimentr` to do these things. 

We're not going to go into detail, but `sentimentr` operates on the sentence level, it provides the option of assigning continuous weights to words, and attempts to account for negation by looking for patterns in user-specified windows around sentiment words. It's built lexicon is a combination of multiple lexicons (so it might have many of the same issues we observed in the NRC), but at least it tries to handle negation out of the box. 

```{r, eval=F}

text_dat.sentr <- text_dat %>%
  filter(doc_num %!in% doc_ids_test) %>% # Select documents for training
  mutate(text = gsub('[Mm]r\\.|[Hh]\\.[Rr]\\.|[Nn][Uu][Mm]\\.', 'mr', text)) %>%
  mutate(sentences = get_sentences(text)) %$%
  sentiment_by(sentences, by= list(doc_num))

saveRDS(text_dat.sentr, file ='../data/text_dat_train_sentimentr_scores.RDS')

```



```{r}
# For some reason looking at text_dat.sentr crashes my notebook, so
# let's look at it in the console
```

Let's look at sentiment estimated with sentimentr at the day level.

```{r, fig.width=8}
dat_tidy.train %>%
  filter(Party != 'Independent') %>%
  distinct(doc_num, .keep_all = T) %>%
  left_join(text_dat.sentr) %>%
  group_by(Party, date) %>%
  summarize(mean_sent = mean(ave_sentiment)) %>%
  ggplot(aes(x = date, y = mean_sent, color=Party)) +
  geom_line() + 
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  geom_point() +
  theme_apa() +
  ggtitle('N of documents across time by party') +
  ylab('N') + 
  xlab('Date') +
  facet_wrap(Party~., ncol=1) +
  geom_hline(yintercept=0)
  
```



<div class="alert alert-success" role="alert">
  <strong>Question:</strong> What does this figure suggest?
</div>

Let's run one of our models with this data and see what it tells us...

```{r}

text_dat.sentr.train <- dat_tidy.train %>%
  filter(Party != 'Independent') %>%
  distinct(doc_num, .keep_all = T) %>%
  left_join(text_dat.sentr) %>%
  group_by(Party, speaker, date) %>%
  summarize(mean_sent = mean(ave_sentiment)) %>%
  left_join(date_grid) %>%
  mutate(date_int_scaled = date_int/100, 
         impeachment_1 = ifelse(date == as_datetime('1998-10-08'), 1, 0),
         impeachment_2 = ifelse(date == as_datetime('1998-12-19'), 1, 0))
  

```



```{r}


text_dat.sentr.train.m1 <- lmer(mean_sent ~ 1 + Party*impeachment_1 + Party*impeachment_2  + (1  | speaker) + (1 + Party | date_int), data=text_dat.sentr.train)

summary(text_dat.sentr.train.m1)
```


<div class="alert alert-success" role="alert">
  <strong>Question:</strong> How does this compare to our previous results?
</div>

```{r}



text_dat.sentr.train.m1.pred <- dat_tidy.train.speaker.pred_grid %>%
  mutate(preds = predict(text_dat.sentr.train.m1, newdata=dat_tidy.train.speaker.pred_grid, allow.new.levels=T))
  


text_dat.sentr.train.m1.pred %>%
  left_join(date_grid) %>%
  ggplot(aes(x = date, y = preds, color=Party)) + 
  geom_line() + 
  geom_point(aes(y = preds), alpha=.25) +
  theme_apa() + 
  scale_colour_manual(values = c("blue", "red")) + 
  theme_apa() +
  geom_vline(xintercept=as.numeric(as_datetime('1998-10-08')), linetype=2, alpha=.25) +
  geom_vline(xintercept=as.numeric(as_datetime('1998-12-19')), linetype=2, alpha=.25) +
  ggtitle('Daily expected proportion of negative language for an average speaker' ) +
  ylab('Speaker proportion negative language') + 
  xlab('Date')

  
```



<div class="alert alert-success" role="alert">
  <strong>Question:</strong> How does this compare to our previous results?
</div>


# Loading LIWC dictionaries in R

It's also possible to work with non-tidy dictionaries in R. For instance, we can use the package `quanteda` to load a LIWC format dictionary and get word counts. While there are a few ways to do this, we'll load the dictionary into a `quanteda` object and then convert our training corpus into a `quanteda` `corpus` object, which is just a native `quanteda` format. We'll then use `quanteda` to create a so-called document feature matrix or `dfm`, using our corpus and LIWC format dictionary.


```{r}

# Load the LIWC-format dictionary
mfd2 <- dictionary(file='../dictionaries/MFD2.liwc',format='LIWC')

# Filter our training data and convert to a data.frame
text_dat.df <- text_dat %>%
    filter(doc_num %!in% doc_ids_test) %>% # Select documents for training
  as.data.frame()

# Create a corpus object
text_dat.corp <- corpus(text_dat.df, docid_field = 'doc_num', text_field = 'text')

#
mfd_counts <- dfm(text_dat.corp, dictionary = mfd2)
```

```{r}

# Convert the dfm to a data.frame
mfd_counts.mat <- matrix(as.numeric(mfd_counts[,1:10]), ncol=10) %>%
  as.data.frame() 

# provide column names 
names(mfd_counts.mat) <- names(mfd2)


text_dat.df <- text_dat.df %>%
  cbind(mfd_counts.mat)

head(text_dat.df %>% dplyr::select(doc_num, contains('.')))

```

